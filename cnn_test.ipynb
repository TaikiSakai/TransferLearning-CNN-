{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/train\"\n",
    "test_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/test\"\n",
    "img_size = 255\n",
    "num_classes = 3\n",
    "class_names = [\"Crazing\", \"Inclusion\", \"Patches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 22:04:26.687175: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2023-11-21 22:04:26.687192: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-21 22:04:26.687196: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-21 22:04:26.687221: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-21 22:04:26.687233: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "augment = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal_and_vertical\"), \n",
    "     layers.RandomRotation(0.2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/\"\n",
    "INPUT_TFRECORD_TRAIN = os.path.join(data_dir, \"train_tfrecords\")\n",
    "INPUT_TFRECORD_TEST = os.path.join(data_dir, \"test_tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTfrecords:\n",
    "\n",
    "    def __init__(self, BATCH_SIZE):\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "\n",
    "\n",
    "    def parse_train(self, serialized):\n",
    "        features = {\"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "                    \"label\": tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        parsed = tf.io.parse_single_example(serialized=serialized, \n",
    "                                            features=features)\n",
    "        \n",
    "        image_raw = parsed[\"image\"]\n",
    "        label_raw = parsed[\"label\"]\n",
    "\n",
    "        images = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "        images = tf.cast(images, tf.float32) / 255\n",
    "        images = tf.reshape(images, [200, 200, 3])\n",
    "\n",
    "        labels = tf.io.decode_raw(label_raw, tf.uint8)\n",
    "        labels = tf.reshape(labels, [3])\n",
    "\n",
    "        return images, labels\n",
    "    \n",
    "\n",
    "    def parse_test(self, serialized):\n",
    "        features = {\"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "                    \"label\": tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        parsed = tf.io.parse_single_example(serialized=serialized, \n",
    "                                            features=features)\n",
    "        \n",
    "        image_raw = parsed[\"image\"]\n",
    "        label_raw = parsed[\"label\"]\n",
    "\n",
    "        images = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "        images = tf.cast(images, tf.float32) / 255\n",
    "        images = tf.reshape(images, [200, 200, 3])\n",
    "\n",
    "        labels = tf.io.decode_raw(label_raw, tf.uint8)\n",
    "        labels = tf.reshape(labels, [3])\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_data = LoadTfrecords(BATCH_SIZE=32)\n",
    "\n",
    "trainset = tf.data.TFRecordDataset(INPUT_TFRECORD_TRAIN)\n",
    "trainset = trainset.map(parse_data.parse_train)\n",
    "trainset = trainset.shuffle(buffer_size=828)\n",
    "trainset = trainset.repeat(-1)\n",
    "trainset = trainset.batch(32)\n",
    "trainset = trainset.prefetch(buffer_size=4)\n",
    "\n",
    "testset = tf.data.TFRecordDataset(INPUT_TFRECORD_TEST)\n",
    "testset = testset.map(parse_data.parse_test)\n",
    "testset = testset.batch(32)\n",
    "testset = testset.prefetch(buffer_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(200, 200, 3))\n",
    "vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 18432)             0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_24 (Dense)            (None, 256)               4718848   \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19434307 (74.14 MB)\n",
      "Trainable params: 19434307 (74.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = vgg16.output\n",
    "x = Flatten(input_shape=vgg16.output_shape[1:])(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "prediction = Dense(3, activation='softmax')(x)\n",
    "model = keras.models.Model(inputs=vgg16.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14714688 (56.13 MB)\n",
      "Trainable params: 7079424 (27.01 MB)\n",
      "Non-trainable params: 7635264 (29.13 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.trainable = True\n",
    "set_trainable = False\n",
    "for layer in vgg16.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    \n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.input_layer.InputLayer object at 0x29a230b50> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x29a230fa0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2874b2af0> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x2817750a0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x175bfa3a0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x281719a00> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x285f5da60> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17f657100> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x2816fe460> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e24e250> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x17e256640> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e2568e0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e2be7c0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e2bed60> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x17e28cf40> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e28cbb0> True\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x17e28c9a0> True\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x16a3ad340> True\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x16a3f45b0> True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg16.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-5), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 23:28:09.216537: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n",
      "2023-11-21 23:28:09.239161: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5585763089763447940\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_12837]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(trainset, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m828\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m32\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtestset, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_2]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_12837]"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainset, \n",
    "                    steps_per_epoch=828//32, \n",
    "                    epochs=10, \n",
    "                    validation_data=testset, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 6, 512)\n"
     ]
    }
   ],
   "source": [
    "print(vgg16.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
