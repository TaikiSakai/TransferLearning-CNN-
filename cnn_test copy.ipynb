{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/train\"\n",
    "test_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/test\"\n",
    "img_size = 255\n",
    "num_classes = 3\n",
    "class_names = [\"Crazing\", \"Inclusion\", \"Patches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 22:59:55.992528: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2023-11-21 22:59:55.992545: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-11-21 22:59:55.992549: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-11-21 22:59:55.992571: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-21 22:59:55.992583: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "augment = keras.Sequential(\n",
    "    [layers.RandomFlip(\"horizontal_and_vertical\"), \n",
    "     layers.RandomRotation(0.2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/taikisakai/git_rep/TransferLearning-CNN-/dataset/\"\n",
    "INPUT_TFRECORD_TRAIN = os.path.join(data_dir, \"train_tfrecords\")\n",
    "INPUT_TFRECORD_TEST = os.path.join(data_dir, \"test_tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadTfrecords:\n",
    "\n",
    "    def __init__(self, BATCH_SIZE):\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "\n",
    "\n",
    "    def parse_train(self, serialized):\n",
    "        features = {\"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "                    \"label\": tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        parsed = tf.io.parse_single_example(serialized=serialized, \n",
    "                                            features=features)\n",
    "        \n",
    "        image_raw = parsed[\"image\"]\n",
    "        label_raw = parsed[\"label\"]\n",
    "\n",
    "        images = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "        images = tf.cast(images, tf.float32) / 255\n",
    "        images = tf.reshape(images, [200, 200, 3])\n",
    "\n",
    "        labels = tf.io.decode_raw(label_raw, tf.float32)\n",
    "        labels = tf.reshape(labels, [3])\n",
    "\n",
    "        return images, labels\n",
    "    \n",
    "\n",
    "    def parse_test(self, serialized):\n",
    "        features = {\"image\": tf.io.FixedLenFeature([], tf.string), \n",
    "                    \"label\": tf.io.FixedLenFeature([], tf.string)}\n",
    "        \n",
    "        parsed = tf.io.parse_single_example(serialized=serialized, \n",
    "                                            features=features)\n",
    "        \n",
    "        image_raw = parsed[\"image\"]\n",
    "        label_raw = parsed[\"label\"]\n",
    "\n",
    "        images = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "        images = tf.cast(images, tf.float32) / 255\n",
    "        images = tf.reshape(images, [200, 200, 3])\n",
    "\n",
    "        labels = tf.io.decode_raw(label_raw, tf.float32)\n",
    "        labels = tf.reshape(labels, [3])\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_data = LoadTfrecords(BATCH_SIZE=32)\n",
    "\n",
    "trainset = tf.data.TFRecordDataset(INPUT_TFRECORD_TRAIN)\n",
    "trainset = trainset.map(parse_data.parse_train)\n",
    "trainset = trainset.shuffle(buffer_size=828)\n",
    "trainset = trainset.repeat(-1)\n",
    "trainset = trainset.batch(32)\n",
    "trainset = trainset.prefetch(buffer_size=4)\n",
    "\n",
    "testset = tf.data.TFRecordDataset(INPUT_TFRECORD_TEST)\n",
    "testset = testset.map(parse_data.parse_test)\n",
    "testset = testset.batch(32)\n",
    "testset = testset.prefetch(buffer_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
    "#conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(200, 200, 3))\n",
    "x = augment(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(3, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-5), \n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-5), \n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 23:00:29.277766: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13396327832007287016\n",
      "2023-11-21 23:00:29.277790: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5677204148285014177\n",
      "2023-11-21 23:00:29.277797: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4776939947513444333\n",
      "2023-11-21 23:00:29.277805: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5371450645822246281\n",
      "2023-11-21 23:00:29.277812: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2794951171050062619\n",
      "2023-11-21 23:00:29.277818: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 242914742123398161\n",
      "2023-11-21 23:00:29.277825: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18286783135220016561\n",
      "2023-11-21 23:00:29.277831: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6211119936579749445\n",
      "2023-11-21 23:00:29.277837: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10263773610135652123\n",
      "2023-11-21 23:00:29.277843: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13524481641884510203\n",
      "2023-11-21 23:00:29.277847: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 9811258813803629121\n",
      "2023-11-21 23:00:29.277853: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14073693198880984407\n",
      "2023-11-21 23:00:29.277859: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5033381776227905259\n",
      "2023-11-21 23:00:29.277865: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1012524545132982259\n",
      "2023-11-21 23:00:29.277871: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5252269820130889605\n",
      "2023-11-21 23:00:29.277877: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15890184093689426241\n",
      "2023-11-21 23:00:29.277883: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 18319823651504968661\n",
      "2023-11-21 23:00:29.277889: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1583942226795919159\n",
      "2023-11-21 23:00:29.277894: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1769928985442301805\n",
      "2023-11-21 23:00:29.277900: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4126136026847672993\n",
      "2023-11-21 23:00:29.277906: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2811601490001975971\n",
      "2023-11-21 23:00:29.277914: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15043276738322209819\n",
      "2023-11-21 23:00:29.277920: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11968862173153222119\n",
      "2023-11-21 23:00:29.277926: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13831444290301116103\n",
      "2023-11-21 23:00:29.277937: I tensorflow/core/framework/local_rendezvous.cc:425] Local rendezvous send item cancelled. Key hash: 491320978902146573\n",
      "2023-11-21 23:00:29.277946: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15962736878405271640\n",
      "2023-11-21 23:00:29.277952: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 11396075168826795314\n",
      "2023-11-21 23:00:29.277957: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17373602843141367360\n",
      "2023-11-21 23:00:29.277963: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14340095282529994942\n",
      "2023-11-21 23:00:29.277968: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6920535621908727848\n",
      "2023-11-21 23:00:29.277973: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 17941899750244166040\n",
      "2023-11-21 23:00:29.277978: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4264194314480806084\n",
      "2023-11-21 23:00:29.277983: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16075375986550540862\n",
      "2023-11-21 23:00:29.277988: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14937403172910961210\n",
      "2023-11-21 23:00:29.277993: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 2457542355213236560\n",
      "2023-11-21 23:00:29.278000: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16543083072165051168\n",
      "2023-11-21 23:00:29.278006: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1292811557598239712\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n\t [[model/sequential/random_flip/stateful_uniform_full_int_1/Bitcast_1/_24]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_3435]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test copy.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test%20copy.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(trainset, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test%20copy.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test%20copy.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test%20copy.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mtestset, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taikisakai/git_rep/TransferLearning-CNN-/cnn_test%20copy.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf-macos/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\nDetected at node Reshape defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n\t [[model/sequential/random_flip/stateful_uniform_full_int_1/Bitcast_1/_24]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 40000 values, but the requested shape has 120000\n\t [[{{node Reshape}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_3435]"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainset, \n",
    "                    steps_per_epoch=20, \n",
    "                    epochs=10, \n",
    "                    validation_data=testset, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-macos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
